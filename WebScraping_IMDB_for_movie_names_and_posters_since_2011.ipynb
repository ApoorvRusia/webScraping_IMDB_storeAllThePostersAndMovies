{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraping_IMDB_for movie names and posters since 2011.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApoorvRusia/webScraping_IMDB_storeAllThePostersAndMovies/blob/master/WebScraping_IMDB_for_movie_names_and_posters_since_2011.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vvrNk-4be163",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Webscraping IMDB\n",
        "\n",
        "### For learning purposes, lets just collect movie posters and movie names since 2011 from IMDB website\n",
        "\n",
        "#### Motivation here is to learn about web scraping and what all we can do with it"
      ]
    },
    {
      "metadata": {
        "id": "WaYUeMwifrjj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, import the necessary libraries. \n",
        "\n",
        "In google-colab these come preinstalled, but they are not part of the python standard library as of the writing of this article."
      ]
    },
    {
      "metadata": {
        "id": "z-sbfuXxwKet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tpR1GZeTDdh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to hit the server and get the necessary page.\n",
        "def request_webpage(url, year_and_month = '2011-01'):\n",
        "  res = requests.get(url + year_and_month + '/')\n",
        "  try:\n",
        "    res.raise_for_status()\n",
        "  except Exception as exc:\n",
        "    print('There was a problem with the request: %s' % (exc))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylg3iaAfgFQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, create an object to store the webpage locally"
      ]
    },
    {
      "metadata": {
        "id": "2bN6hq4gD0-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Actuall URL should be 'https://www.imdb.com/movies-coming-soon/2011-01/',\n",
        "#We will send the year and month value dynamically into the url to fetch different values\n",
        "url = 'https://www.imdb.com/movies-coming-soon/'\n",
        "coming_soon_page = request_webpage(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkRisHF8is8u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a look at what data we have got in html"
      ]
    },
    {
      "metadata": {
        "id": "aS3021uLECI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#coming_soon_page.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eyu8aru5izoA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The 'prettify' function will help to make this a bit more human readable"
      ]
    },
    {
      "metadata": {
        "id": "MvU9DX3mdERj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "coming_soon_soup = BeautifulSoup(coming_soon_page.text)\n",
        "#print(coming_soon_soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UgXtHBmON6a3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, let's find the images.\n",
        "\n",
        "One can locate an HTML element by right clicking on the webpage and selecting 'inspect'.\n",
        "\n",
        "The code below is looking for an element like this: \n",
        "\n",
        "< div class=\"list detail\" >... (content)...< /div >"
      ]
    },
    {
      "metadata": {
        "id": "4HTV5ty2KRDi",
        "colab_type": "code",
        "outputId": "66623836-1ec1-4636-96bf-1404024ccb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "#find the main div tag which contains all the information related to movies.\n",
        "details = coming_soon_soup.find('div', attrs = {'class': 'list detail'})\n",
        "#inside the div tag, lets find all the img tags\n",
        "image_details = details.find_all('img')\n",
        "\n",
        "#this list comprehension will get all the 'src' data (urls) of the posters (as class name has the word poster in it),\n",
        "#while filter out icons for ratings\n",
        "image_list = [x['src'] for x in image_details if 'poster' in x['class']]\n",
        "image_list"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://m.media-amazon.com/images/M/MV5BMzc3MjYxNzg2N15BMl5BanBnXkFtZTcwNzQyMTkwNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTUxMjQ0NjE3OV5BMl5BanBnXkFtZTcwODIxNDEwNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTcwOTMwMDYyMl5BMl5BanBnXkFtZTcwMzAxMjMyNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMzg3MDUwMTI1OV5BMl5BanBnXkFtZTcwNzY0NDIxNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTM4MTUwNDg0OF5BMl5BanBnXkFtZTcwMjUyODYxNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTc3MjkyMzk4N15BMl5BanBnXkFtZTcwODQxMDg5Mw@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTkxOTI3Njc4MF5BMl5BanBnXkFtZTcwMzI0NTIzNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTQxMTgyNDc5M15BMl5BanBnXkFtZTcwMzk4OTM5Mw@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTg2MDQ1NTEzNl5BMl5BanBnXkFtZTcwOTgxNTMyNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTg5MTc5MTM3Ml5BMl5BanBnXkFtZTcwMDI2NzgwNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMjEyMjk1NjI1M15BMl5BanBnXkFtZTcwODcyNjAxNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTcxNTAxMTMzNF5BMl5BanBnXkFtZTcwMjQ1MDAxNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMzI4OTQ0MDQyNl5BMl5BanBnXkFtZTcwODY5MjQwNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTY2NDAxNjgwMF5BMl5BanBnXkFtZTcwNDc3NzQxNA@@._V1_UY209_CR0,0,140,209_AL_.jpg',\n",
              " 'https://m.media-amazon.com/images/M/MV5BMTM5NjUzOTMxOV5BMl5BanBnXkFtZTcwNzgwNTMzNA@@._V1_UX140_CR0,0,140,209_AL_.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "VkiEUuR2CO9-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can get the full size image URLs by removing everything between '_V1_' and '.jpg'"
      ]
    },
    {
      "metadata": {
        "id": "dRAEhh48OuP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_url = image_list[0]\n",
        "#find the position of '_V1_' in the img url to remove anything after it to get the full size of the image.\n",
        "slice_index = image_url.find('_V1_')\n",
        "#print(slice_index)\n",
        "full_size_image_url = image_url[:slice_index] + '_V1_.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KcnjOWUrQVFS",
        "colab_type": "code",
        "outputId": "f3d94366-92f8-4389-912c-8515b3b99db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Now let's see how the image url looks like. Click the url to see the full image.\n",
        "full_size_image_url"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://m.media-amazon.com/images/M/MV5BMzc3MjYxNzg2N15BMl5BanBnXkFtZTcwNzQyMTkwNA@@._V1_.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "nUGfP42Y5wYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#now lets get the image from the server\n",
        "img_res = request_webpage(full_size_image_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0B3yoJqW7mC_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let us save the images \n",
        "imageFile = open('MoviePoster0'+'.jpg', 'wb')\n",
        "for chunk in img_res.iter_content(100000):\n",
        "  imageFile.write(chunk)\n",
        "imageFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1DtWYcoCFrP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can find files (in colab) by clicking the '>' icon on the top-left side of the screen. You may need to refresh."
      ]
    },
    {
      "metadata": {
        "id": "-PR_-EokTKw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Find the names of the movies for this month \n",
        "\n",
        "And save them in a list"
      ]
    },
    {
      "metadata": {
        "id": "uHUc9dWCNGMo",
        "colab_type": "code",
        "outputId": "2912b42d-307c-4e28-cf06-0bdd2651df95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "current_date = datetime.today().strftime(\"%Y-%m\")\n",
        "print('The current year and months is ',current_date)\n",
        "movie_page = BeautifulSoup(request_webpage(url, current_date).text)\n",
        "\n",
        "div_page_details = movie_page.find('div', attrs = {'class': 'list detail'})\n",
        "#inside the div tag, lets find all the img tags\n",
        "image_details = div_page_details.find_all('img')\n",
        "\n",
        "name_list = [x['alt'] for x in image_details if 'poster' in x['class']]\n",
        "name_list"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current year and months is  2019-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Miss Bala (2019) Poster',\n",
              " 'Arctic (2018) Poster',\n",
              " 'Ek Ladki Ko Dekha Toh Aisa Laga (2019) Poster',\n",
              " 'Ahlat Agaci (2018) Poster',\n",
              " 'The Lego Movie 2: The Second Part (2019) Poster',\n",
              " 'What Men Want (2019) Poster',\n",
              " 'Cold Pursuit (2019) Poster',\n",
              " 'The Prodigy (2019) Poster',\n",
              " 'Todos lo saben (2018) Poster',\n",
              " 'Under the Eiffel Tower (2018) Poster',\n",
              " 'Chokehold (2019) Poster',\n",
              " 'xiao zhu pei qi guo da nian (2019) Poster',\n",
              " 'The Final Wish (2018) Poster',\n",
              " 'Happy Death Day 2U (2019) Poster',\n",
              " 'Alita: Battle Angel (2019) Poster',\n",
              " 'Fighting with My Family (2019) Poster',\n",
              " \"Isn't It Romantic (2019) Poster\",\n",
              " 'Pájaros de verano (2018) Poster',\n",
              " 'Ruben Brandt, Collector (2018) Poster',\n",
              " 'Donnybrook (2018) Poster',\n",
              " 'Plaire, aimer et courir vite (2018) Poster',\n",
              " 'How to Train Your Dragon: The Hidden World (2019) Poster',\n",
              " 'Total Dhamaal (2019) Poster',\n",
              " 'Run the Race (2019) Poster',\n",
              " 'The Turning (2020) Poster']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "hdKZ_a2TTyix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Collect all of the movie posters (for this month).\n",
        "\n",
        "And, put them in a folder."
      ]
    },
    {
      "metadata": {
        "id": "RThfk-Bd_P97",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#create the folder with the name year-month\n",
        "try:\n",
        "  os.makedirs(current_date)\n",
        "except:\n",
        "  print('failed gracefully, you probably already made the folder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSTTH27ITLJZ",
        "colab_type": "code",
        "outputId": "8b108db9-01ea-4655-f2ac-728077a6a275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(image_list)):\n",
        "  image_url = image_list[i]\n",
        "  slice_index = image_url.find('_V1_')\n",
        "  full_size_image_url = image_url[:slice_index] + '_V1_.jpg'\n",
        "  img_res = request_webpage(full_size_image_url)\n",
        "  try:\n",
        "    imageFile = open(os.path.join(current_date, name_list[i] + '.jpg'), 'wb')\n",
        "    for chunk in img_res.iter_content(100000):\n",
        "      imageFile.write(chunk)\n",
        "    imageFile.close()\n",
        "  except Exception as exc:\n",
        "    print('There was a problem with writing the file for %s: %s' % (name_list[i], exc))\n",
        "    \n",
        "print('All Finished')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZV313V2UutF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Collect a year's worth of movie posters, placing them in folders by month.\n"
      ]
    },
    {
      "metadata": {
        "id": "9B9fe0bmEL-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def collect_media_info(date):\n",
        "  \n",
        "  soup = BeautifulSoup(request_webpage(url, date).text)\n",
        "  details = soup.find('div', attrs = {'class': 'list detail'})\n",
        "  image_details = details.find_all('img')\n",
        "  \n",
        "  image_list = [x['src'] for x in image_details if 'poster' in x['class']]\n",
        "  name_list = [x['alt'] for x in image_details if 'poster' in x['class']]\n",
        "  return (image_list, name_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ZQfdtitCarY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_month_of_posters(images, names, date):\n",
        "  try:\n",
        "    os.makedirs(date)\n",
        "  except:\n",
        "    print('failed gracefully, you probably already made the folder')\n",
        "    \n",
        "  for i in range(len(images)):\n",
        "    image_url = images[i]\n",
        "    slice_index = image_url.find('_V1_')\n",
        "    full_size_image_url = image_url[:slice_index] + '_V1_.jpg'\n",
        "    img_res = request_webpage(full_size_image_url)\n",
        "    name = names[i]\n",
        "    if ('/' in name): # because file names can't have a slash\n",
        "      name = name.replace('/', '-') \n",
        "    try:\n",
        "      imageFile = open(os.path.join(date, name + '.jpg'), 'wb')\n",
        "      for chunk in img_res.iter_content(100000):\n",
        "        imageFile.write(chunk)\n",
        "      imageFile.close()\n",
        "    except Exception as exc:\n",
        "      print('There was a problem with writing the file for %s: %s' % (names[i], exc))\n",
        "    \n",
        "  print('All Finished with %s' % (date))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNP2MEi0Xh05",
        "colab_type": "code",
        "outputId": "3a3fc5bc-21b0-40f6-a30c-d8bc9b0bb0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# month numbers for the URLs\n",
        "month_nums = [str(x+1).zfill(2) for x in range(12)]\n",
        "month_nums"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "HPiifBKmUaba",
        "colab_type": "code",
        "outputId": "f6cc1378-31c9-471d-cb61-992a7f97a4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "year = '2019'\n",
        "for ii in month_nums:\n",
        "  date = year + '-' + ii\n",
        "  images, names = collect_media_info(date)\n",
        "  download_month_of_posters(images, names, date)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Finished with 2019-01\n",
            "All Finished with 2019-02\n",
            "All Finished with 2019-03\n",
            "All Finished with 2019-04\n",
            "All Finished with 2019-05\n",
            "All Finished with 2019-06\n",
            "All Finished with 2019-07\n",
            "All Finished with 2019-08\n",
            "All Finished with 2019-09\n",
            "All Finished with 2019-10\n",
            "All Finished with 2019-11\n",
            "All Finished with 2019-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N6wT-eb5H9Lw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Collect all the movie posters since the start of this page (2011-01)\n",
        "\n",
        "And, put it in different folders"
      ]
    },
    {
      "metadata": {
        "id": "Zk3fH66qILI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_year = datetime.now().year\n",
        "print(current_year)\n",
        "year = 2011\n",
        "while(int(year) <= int(current_year)):\n",
        "  for ii in month_nums:\n",
        "    folder_name = str(year) + '-' + ii\n",
        "    #print(folder_name)\n",
        "    images, names = collect_media_info(folder_name)\n",
        "    download_month_of_posters(images, names, folder_name)\n",
        "    \n",
        "  year = year+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ObXJuutBmQyL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Zip all the files you have collected in order to download them on your local machine (without a million clicks)\n",
        "\n",
        "See this article for how to go about zipping: https://www.geeksforgeeks.org/working-zip-files-python/"
      ]
    },
    {
      "metadata": {
        "id": "jzEA92ofSqEn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4bra_onoMCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# code for deleting a directory\n",
        "# in case you make a mistake and want to clean up: \n",
        "!rm -rf '2010-01' # '2018-01' is a folder of files to delete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65uispHwSqok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_file_paths(directory): \n",
        "  file_paths = []\n",
        "  files = os.listdir(directory)\n",
        "  for filename in files: \n",
        "    filepath = os.path.join(directory, filename)\n",
        "    file_paths.append(filepath)\n",
        "  return file_paths "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2DR1pKMJAkj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "year = 2011\n",
        "cwd_file_paths = []\n",
        "while(year <= datetime.now().year):\n",
        "  \n",
        "  for i in range(12):\n",
        "    date = str(year) + '-' + str(i+1).zfill(2)\n",
        "    cwd_file_paths += get_file_paths(date)\n",
        "  year+=1\n",
        "#print(cwd_file_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fP2rvX7IX34l",
        "colab_type": "code",
        "outputId": "88a9221d-ca7d-4c6e-a881-d3da827d6ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "'''print('The following files will be zipped:') \n",
        "for file_name in cwd_file_paths: \n",
        "  print(file_name) \n",
        "  \n",
        "'''\n",
        "\n",
        "with ZipFile('Movie-posters.zip','w') as zip: \n",
        "  for file in tqdm(cwd_file_paths):\n",
        "    zip.write(file)\n",
        "  \n",
        "print('All files zipped successfully!')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3393/3393 [01:08<00:00, 49.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All files zipped successfully!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oWOubZ2wWfZF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## To delete the folders and files after zipping it"
      ]
    },
    {
      "metadata": {
        "id": "1IRoM8U1R-ka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#To delete all the folders, we can use this command.\n",
        "#!rm -rf '2019-01'\n",
        "import re, shutil\n",
        "path = '.'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for name in files:\n",
        "  if re.match('^\\d+', name, flags=0):\n",
        "    shutil.rmtree(name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}